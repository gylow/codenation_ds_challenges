{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596551774235",
   "display_name": "Python 3.7.7 64-bit ('venv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_target = 'NU_NOTA_MT'\n",
    "name_id = 'NU_INSCRICAO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analisa os dados de teste e de treino\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "print(f'Train shape: {df_train.shape}, Test shape: {df_test.shape}')\n",
    "\n",
    "if name_target not in df_train.columns :\n",
    "    print('ERROR: dataframe de treino não possui target')\n",
    "    \n",
    "elif df_test.columns.size >= (df_train.drop(columns=name_target).columns.size)\\\n",
    "        and all(elem in df_test for elem in df_train.drop(columns=name_target).columns) :\n",
    "    print('ALERT: dataframes de teste e treino ok')\n",
    "\n",
    "elif all(df_train[df_test.columns].columns == df_test.columns) :\n",
    "    print('DONE: convertendo colunas dataframe de treino igual ao de teste + target')\n",
    "    df_train = pd.concat([df_train[df_test.columns], df_train[name_target]], axis=1)\n",
    "    print('DONE: gravando dataframe de treino formatado')\n",
    "    df_train.to_csv('../data/train.csv', index=False)\n",
    "else :\n",
    "    print('ERROR: colunas dos Data frames de treino e testes são diferentes')\n",
    "\n",
    "print(df_train.info())\n",
    "del df_test, df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Análise de dados nulos e zerados\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "print(f'dados Nulos: {df_train[(df_train[\"TP_PRESENCA_LC\"] == 0) | (df_train[\"TP_PRESENCA_LC\"] == 2) ][name_target].unique()}')\n",
    "print(f'dados Zerados: {df_train[(df_train[\"NU_NOTA_LC\"] == 0)][name_target].unique()}')\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_source import DataSource\n",
    "lin_null = [('TP_PRESENCA_LC', 0), ('TP_PRESENCA_LC', 2)]\n",
    "lin_zero = [('NU_NOTA_LC', 0)]\n",
    "data = DataSource(name_id=name_id, name_target=name_target, rows_remove=(lin_null + lin_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Feature\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.pylabtools import figsize\n",
    "%matplotlib inline\n",
    "figsize(12, 8)\n",
    "sns.set()\n",
    "sns.heatmap(df_train.corr(), square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = df_train['NU_IDADE']\n",
    "print(var.value_counts(dropna=False))\n",
    "print(f'mean: {var.mean()}')\n",
    "print(f'median: {var.median()}')\n",
    "print(f'mode: {var.mode()}')\n",
    "sns.distplot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.scatterplot(var, df_train[name_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.lineplot(var, df_train[name_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.qqplot(var, fit=True, line=\"45\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional manual analise columns\n",
    "col_analise = [             #TYPE  ->[FILLNA  ENCODE ->[DROP_FIRST]]\n",
    "    ('NU_INSCRICAO',        None), # only unique values\n",
    "    ('CO_UF_RESIDENCIA',    None), # duplicated\n",
    "    ('SG_UF_RESIDENCIA',    'cat',  None,   False),\n",
    "    ('NU_IDADE',            'num',  None,   False),\n",
    "    ('TP_SEXO',             'cat',  None,   False),\n",
    "    #('TP_COR_RACA',         'cat'),\n",
    "    ('TP_COR_RACA',         'cat',  None,   True,   True),\n",
    "    ('TP_NACIONALIDADE',    None), # insignificant correlation\n",
    "    ('TP_ST_CONCLUSAO',     'cat',  None,   False),\n",
    "    ('TP_ANO_CONCLUIU',     None), # missing values\n",
    "    #('TP_ESCOLA',           False),\n",
    "    ('TP_ESCOLA',           'cat',  None,   True,   True),\n",
    "    ('TP_ENSINO',           'cat',  None,   True,   False),\n",
    "    ('IN_TREINEIRO',        'cat',  None,   False),\t\n",
    "    ('TP_DEPENDENCIA_ADM_ESC','cat',None,   True,   False),\n",
    "    ('IN_BAIXA_VISAO',      None),\t\n",
    "    ('IN_CEGUEIRA',         None), \t\n",
    "    ('IN_SURDEZ',           None), \t\n",
    "    ('IN_DISLEXIA',         None), \t\n",
    "    ('IN_DISCALCULIA',      None), \t\n",
    "    ('IN_SABATISTA',        None), \t\n",
    "    ('IN_GESTANTE',         None), \t\n",
    "    ('IN_IDOSO',            None), \t\n",
    "    ('TP_PRESENCA_CN',      None), \t\n",
    "    ('TP_PRESENCA_CH',      None), \t\n",
    "    ('TP_PRESENCA_LC',      None), \t\n",
    "    ('CO_PROVA_CN',         None), \t\n",
    "    ('CO_PROVA_CH',         None), \t\n",
    "    ('CO_PROVA_LC',         None), \t\n",
    "    ('CO_PROVA_MT',         None), \t\n",
    "    ('NU_NOTA_CN',          'num',   459.8,  False),\t\n",
    "    ('NU_NOTA_CH',          'num',   532.0,  False),\t\n",
    "    ('NU_NOTA_LC',          'num',   None,   False),\t\n",
    "    #('NU_NOTA_REDACAO',     'num',   None,   False),\t\n",
    "    ('NU_NOTA_REDACAO',     None),\t\n",
    "    ('TP_LINGUA',           'cat',   None,   False),\n",
    "    ('TP_STATUS_REDACAO',   'cat'),\t\n",
    "    #('NU_NOTA_COMP1',       None),\t\n",
    "    ('NU_NOTA_COMP1',       'num',   None,   False),\t\n",
    "    #('NU_NOTA_COMP2',       None),\t\n",
    "    ('NU_NOTA_COMP2',       'num',   None,   False),\n",
    "    #('NU_NOTA_COMP3',       None),\t\n",
    "    ('NU_NOTA_COMP3',       'num',   None,   False),\n",
    "    #('NU_NOTA_COMP4',       None),\n",
    "    ('NU_NOTA_COMP4',       'num',   None,   False),\n",
    "    #('NU_NOTA_COMP5',       None),\n",
    "    ('NU_NOTA_COMP5',       'num',   None,   False),\n",
    "    ('Q001',                'cat',   None,   False),\t\n",
    "    ('Q002',                'cat',   None,   False),\n",
    "    ('Q006',                'cat',   None,   False),\n",
    "    ('Q024',                'cat',   None,   False),\n",
    "    ('Q025',                'cat',   None,   False),\n",
    "    #('Q026',                False),\t\n",
    "    ('Q026',                'cat',   None,   False),\n",
    "    ('Q027',                None), # missing values\t\n",
    "    ('Q047',                'cat',   None,   False),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessing\n",
    "pre = Preprocessing(data, col_analise=col_analise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "drop: NU_INSCRICAO\ndrop: CO_UF_RESIDENCIA\nuse: SG_UF_RESIDENCIA\nuse: NU_IDADE\nuse: TP_SEXO\nuse: TP_COR_RACA\n\tencode: [0 1 2 3 4 5]\n\t\tdrop value: 0\ndrop: TP_NACIONALIDADE\nuse: TP_ST_CONCLUSAO\ndrop: TP_ANO_CONCLUIU\nuse: TP_ESCOLA\n\tencode: [1 2 3 4]\n\t\tdrop value: 1\nuse: TP_ENSINO\n\tencode: [1. 2. 3.]\nuse: IN_TREINEIRO\nuse: TP_DEPENDENCIA_ADM_ESC\n\tencode: [1. 2. 3. 4.]\ndrop: IN_BAIXA_VISAO\ndrop: IN_CEGUEIRA\ndrop: IN_SURDEZ\ndrop: IN_DISLEXIA\ndrop: IN_DISCALCULIA\ndrop: IN_SABATISTA\ndrop: IN_GESTANTE\ndrop: IN_IDOSO\ndrop: TP_PRESENCA_CN\ndrop: TP_PRESENCA_CH\ndrop: TP_PRESENCA_LC\ndrop: CO_PROVA_CN\ndrop: CO_PROVA_CH\ndrop: CO_PROVA_LC\ndrop: CO_PROVA_MT\nuse: NU_NOTA_CN\n\tfill na with: 459.8\nuse: NU_NOTA_CH\n\tfill na with: 532.0\nuse: NU_NOTA_LC\ndrop: NU_NOTA_REDACAO\nuse: TP_LINGUA\ndrop: TP_STATUS_REDACAO\nuse: NU_NOTA_COMP1\nuse: NU_NOTA_COMP2\nuse: NU_NOTA_COMP3\nuse: NU_NOTA_COMP4\nuse: NU_NOTA_COMP5\nuse: Q001\nuse: Q002\nuse: Q006\nuse: Q024\nuse: Q025\nuse: Q026\ndrop: Q027\nuse: Q047\nCreating DataFrame for Data Manipulation\n                            missing_perc  unique_perc    dtype\nSG_UF_RESIDENCIA                     0.0         0.27   object\nNU_IDADE                             0.0         0.52    int64\nTP_SEXO                              0.0         0.02   object\nTP_ST_CONCLUSAO                      0.0         0.04    int64\nIN_TREINEIRO                         0.0         0.02    int64\nNU_NOTA_CN                           0.0        26.47  float64\nNU_NOTA_CH                           0.0        29.24  float64\nNU_NOTA_LC                           0.0        27.38  float64\nTP_LINGUA                            0.0         0.02    int64\nNU_NOTA_COMP1                        0.0         0.15  float64\nNU_NOTA_COMP2                        0.0         0.13  float64\nNU_NOTA_COMP3                        0.0         0.12  float64\nNU_NOTA_COMP4                        0.0         0.14  float64\nNU_NOTA_COMP5                        0.0         0.14  float64\nQ001                                 0.0         0.08   object\nQ002                                 0.0         0.08   object\nQ006                                 0.0         0.17   object\nQ024                                 0.0         0.05   object\nQ025                                 0.0         0.02   object\nQ026                                 0.0         0.03   object\nQ047                                 0.0         0.05   object\nNU_NOTA_MT                           0.0        33.64  float64\nTP_COR_RACA_1                        0.0         0.02    int64\nTP_COR_RACA_2                        0.0         0.02    int64\nTP_COR_RACA_3                        0.0         0.02    int64\nTP_COR_RACA_4                        0.0         0.02    int64\nTP_COR_RACA_5                        0.0         0.02    int64\nTP_ESCOLA_2                          0.0         0.02    int64\nTP_ESCOLA_3                          0.0         0.02    int64\nTP_ESCOLA_4                          0.0         0.02    int64\nTP_ENSINO_1.0                        0.0         0.02    int64\nTP_ENSINO_2.0                        0.0         0.02    int64\nTP_ENSINO_3.0                        0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_1.0           0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_2.0           0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_3.0           0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_4.0           0.0         0.02    int64\nALERT: Droping columns with missing values > 0% :\nSeries([], Name: missing_perc, dtype: float64)\nALERT: Droping columns with unique values >= 100% :\nSeries([], Name: unique_perc, dtype: float64)\nCreating list with numeric features\nNumeric Feature >>>> ['NU_IDADE', 'TP_ST_CONCLUSAO', 'IN_TREINEIRO', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'TP_LINGUA', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'TP_COR_RACA_1', 'TP_COR_RACA_2', 'TP_COR_RACA_3', 'TP_COR_RACA_4', 'TP_COR_RACA_5', 'TP_ESCOLA_2', 'TP_ESCOLA_3', 'TP_ESCOLA_4', 'TP_ENSINO_1.0', 'TP_ENSINO_2.0', 'TP_ENSINO_3.0', 'TP_DEPENDENCIA_ADM_ESC_1.0', 'TP_DEPENDENCIA_ADM_ESC_2.0', 'TP_DEPENDENCIA_ADM_ESC_3.0', 'TP_DEPENDENCIA_ADM_ESC_4.0']\nCreating list with categoric features\nCategoric Feature >>>> ['SG_UF_RESIDENCIA', 'TP_SEXO', 'Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047']\nFeature Normalization and Encoding:\nSetting Y as target and Removing target from train dataframe\nFeature Fit and Transform in train dataframe\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10126 entries, 0 to 13729\nData columns (total 36 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   NU_IDADE                    10126 non-null  float64\n 1   TP_ST_CONCLUSAO             10126 non-null  float64\n 2   IN_TREINEIRO                10126 non-null  float64\n 3   NU_NOTA_CN                  10126 non-null  float64\n 4   NU_NOTA_CH                  10126 non-null  float64\n 5   NU_NOTA_LC                  10126 non-null  float64\n 6   TP_LINGUA                   10126 non-null  float64\n 7   NU_NOTA_COMP1               10126 non-null  float64\n 8   NU_NOTA_COMP2               10126 non-null  float64\n 9   NU_NOTA_COMP3               10126 non-null  float64\n 10  NU_NOTA_COMP4               10126 non-null  float64\n 11  NU_NOTA_COMP5               10126 non-null  float64\n 12  TP_COR_RACA_1               10126 non-null  float64\n 13  TP_COR_RACA_2               10126 non-null  float64\n 14  TP_COR_RACA_3               10126 non-null  float64\n 15  TP_COR_RACA_4               10126 non-null  float64\n 16  TP_COR_RACA_5               10126 non-null  float64\n 17  TP_ESCOLA_2                 10126 non-null  float64\n 18  TP_ESCOLA_3                 10126 non-null  float64\n 19  TP_ESCOLA_4                 10126 non-null  float64\n 20  TP_ENSINO_1.0               10126 non-null  float64\n 21  TP_ENSINO_2.0               10126 non-null  float64\n 22  TP_ENSINO_3.0               10126 non-null  float64\n 23  TP_DEPENDENCIA_ADM_ESC_1.0  10126 non-null  float64\n 24  TP_DEPENDENCIA_ADM_ESC_2.0  10126 non-null  float64\n 25  TP_DEPENDENCIA_ADM_ESC_3.0  10126 non-null  float64\n 26  TP_DEPENDENCIA_ADM_ESC_4.0  10126 non-null  float64\n 27  SG_UF_RESIDENCIA            10126 non-null  float64\n 28  TP_SEXO                     10126 non-null  float64\n 29  Q001                        10126 non-null  float64\n 30  Q002                        10126 non-null  float64\n 31  Q006                        10126 non-null  float64\n 32  Q024                        10126 non-null  float64\n 33  Q025                        10126 non-null  float64\n 34  Q026                        10126 non-null  float64\n 35  Q047                        10126 non-null  float64\ndtypes: float64(36)\nmemory usage: 3.2 MB\n"
    }
   ],
   "source": [
    "#testes\n",
    "df_new = pre.process()[0]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from experiments import Experiments\n",
    "#Experiments(data).run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training import ModelTraining\n",
    "model = ModelTraining(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training preprocessing\ndrop: NU_INSCRICAO\ndrop: CO_UF_RESIDENCIA\nuse: SG_UF_RESIDENCIA\nuse: NU_IDADE\nuse: TP_SEXO\nuse: TP_COR_RACA\n\tencode: [0 1 2 3 4 5]\n\t\tdrop value: 0\ndrop: TP_NACIONALIDADE\nuse: TP_ST_CONCLUSAO\ndrop: TP_ANO_CONCLUIU\nuse: TP_ESCOLA\n\tencode: [1 2 3 4]\n\t\tdrop value: 1\nuse: TP_ENSINO\n\tencode: [1. 2. 3.]\nuse: IN_TREINEIRO\nuse: TP_DEPENDENCIA_ADM_ESC\n\tencode: [1. 2. 3. 4.]\ndrop: IN_BAIXA_VISAO\ndrop: IN_CEGUEIRA\ndrop: IN_SURDEZ\ndrop: IN_DISLEXIA\ndrop: IN_DISCALCULIA\ndrop: IN_SABATISTA\ndrop: IN_GESTANTE\ndrop: IN_IDOSO\ndrop: TP_PRESENCA_CN\ndrop: TP_PRESENCA_CH\ndrop: TP_PRESENCA_LC\ndrop: CO_PROVA_CN\ndrop: CO_PROVA_CH\ndrop: CO_PROVA_LC\ndrop: CO_PROVA_MT\nuse: NU_NOTA_CN\n\tfill na with: 459.8\nuse: NU_NOTA_CH\n\tfill na with: 532.0\nuse: NU_NOTA_LC\ndrop: NU_NOTA_REDACAO\nuse: TP_LINGUA\ndrop: TP_STATUS_REDACAO\nuse: NU_NOTA_COMP1\nuse: NU_NOTA_COMP2\nuse: NU_NOTA_COMP3\nuse: NU_NOTA_COMP4\nuse: NU_NOTA_COMP5\nuse: Q001\nuse: Q002\nuse: Q006\nuse: Q024\nuse: Q025\nuse: Q026\ndrop: Q027\nuse: Q047\nCreating DataFrame for Data Manipulation\n                            missing_perc  unique_perc    dtype\nSG_UF_RESIDENCIA                     0.0         0.27   object\nNU_IDADE                             0.0         0.52    int64\nTP_SEXO                              0.0         0.02   object\nTP_ST_CONCLUSAO                      0.0         0.04    int64\nIN_TREINEIRO                         0.0         0.02    int64\nNU_NOTA_CN                           0.0        26.47  float64\nNU_NOTA_CH                           0.0        29.24  float64\nNU_NOTA_LC                           0.0        27.38  float64\nTP_LINGUA                            0.0         0.02    int64\nNU_NOTA_COMP1                        0.0         0.15  float64\nNU_NOTA_COMP2                        0.0         0.13  float64\nNU_NOTA_COMP3                        0.0         0.12  float64\nNU_NOTA_COMP4                        0.0         0.14  float64\nNU_NOTA_COMP5                        0.0         0.14  float64\nQ001                                 0.0         0.08   object\nQ002                                 0.0         0.08   object\nQ006                                 0.0         0.17   object\nQ024                                 0.0         0.05   object\nQ025                                 0.0         0.02   object\nQ026                                 0.0         0.03   object\nQ047                                 0.0         0.05   object\nNU_NOTA_MT                           0.0        33.64  float64\nTP_COR_RACA_1                        0.0         0.02    int64\nTP_COR_RACA_2                        0.0         0.02    int64\nTP_COR_RACA_3                        0.0         0.02    int64\nTP_COR_RACA_4                        0.0         0.02    int64\nTP_COR_RACA_5                        0.0         0.02    int64\nTP_ESCOLA_2                          0.0         0.02    int64\nTP_ESCOLA_3                          0.0         0.02    int64\nTP_ESCOLA_4                          0.0         0.02    int64\nTP_ENSINO_1.0                        0.0         0.02    int64\nTP_ENSINO_2.0                        0.0         0.02    int64\nTP_ENSINO_3.0                        0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_1.0           0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_2.0           0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_3.0           0.0         0.02    int64\nTP_DEPENDENCIA_ADM_ESC_4.0           0.0         0.02    int64\nALERT: Droping columns with missing values > 0% :\nSeries([], Name: missing_perc, dtype: float64)\nALERT: Droping columns with unique values >= 100% :\nSeries([], Name: unique_perc, dtype: float64)\nCreating list with numeric features\nNumeric Feature >>>> ['NU_IDADE', 'TP_ST_CONCLUSAO', 'IN_TREINEIRO', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'TP_LINGUA', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'TP_COR_RACA_1', 'TP_COR_RACA_2', 'TP_COR_RACA_3', 'TP_COR_RACA_4', 'TP_COR_RACA_5', 'TP_ESCOLA_2', 'TP_ESCOLA_3', 'TP_ESCOLA_4', 'TP_ENSINO_1.0', 'TP_ENSINO_2.0', 'TP_ENSINO_3.0', 'TP_DEPENDENCIA_ADM_ESC_1.0', 'TP_DEPENDENCIA_ADM_ESC_2.0', 'TP_DEPENDENCIA_ADM_ESC_3.0', 'TP_DEPENDENCIA_ADM_ESC_4.0']\nCreating list with categoric features\nCategoric Feature >>>> ['SG_UF_RESIDENCIA', 'TP_SEXO', 'Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047']\nFeature Normalization and Encoding:\nSetting Y as target and Removing target from train dataframe\nFeature Fit and Transform in train dataframe\nTraining Model\n"
    }
   ],
   "source": [
    "trained_model = model.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Preprocessing Data\ndrop: NU_INSCRICAO\ndrop: CO_UF_RESIDENCIA\nuse: SG_UF_RESIDENCIA\nuse: NU_IDADE\nuse: TP_SEXO\nuse: TP_COR_RACA\n\tencode: [0 1 2 3 4 5]\n\t\tdrop value: 0\ndrop: TP_NACIONALIDADE\nuse: TP_ST_CONCLUSAO\ndrop: TP_ANO_CONCLUIU\nuse: TP_ESCOLA\n\tencode: [1 2 3]\n\t\tdrop value: 1\nuse: TP_ENSINO\n\tencode: [1. 2. 3.]\nuse: IN_TREINEIRO\nuse: TP_DEPENDENCIA_ADM_ESC\n\tencode: [1. 2. 3. 4.]\ndrop: IN_BAIXA_VISAO\ndrop: IN_CEGUEIRA\ndrop: IN_SURDEZ\ndrop: IN_DISLEXIA\ndrop: IN_DISCALCULIA\ndrop: IN_SABATISTA\ndrop: IN_GESTANTE\ndrop: IN_IDOSO\ndrop: TP_PRESENCA_CN\ndrop: TP_PRESENCA_CH\ndrop: TP_PRESENCA_LC\ndrop: CO_PROVA_CN\ndrop: CO_PROVA_CH\ndrop: CO_PROVA_LC\ndrop: CO_PROVA_MT\nuse: NU_NOTA_CN\n\tfill na with: 459.8\nuse: NU_NOTA_CH\n\tfill na with: 532.0\nuse: NU_NOTA_LC\ndrop: NU_NOTA_REDACAO\nuse: TP_LINGUA\ndrop: TP_STATUS_REDACAO\nuse: NU_NOTA_COMP1\nuse: NU_NOTA_COMP2\nuse: NU_NOTA_COMP3\nuse: NU_NOTA_COMP4\nuse: NU_NOTA_COMP5\nuse: Q001\nuse: Q002\nuse: Q006\nuse: Q024\nuse: Q025\nuse: Q026\ndrop: Q027\nuse: Q047\nCreating DataFrame for Data Manipulation\n                            missing_perc  unique_perc    dtype\nSG_UF_RESIDENCIA                     0.0         0.80   object\nNU_IDADE                             0.0         1.33    int64\nTP_SEXO                              0.0         0.06   object\nTP_ST_CONCLUSAO                      0.0         0.12    int64\nIN_TREINEIRO                         0.0         0.06    int64\nNU_NOTA_CN                           0.0        53.42  float64\nNU_NOTA_CH                           0.0        57.63  float64\nNU_NOTA_LC                           0.0        54.46  float64\nTP_LINGUA                            0.0         0.06    int64\nNU_NOTA_COMP1                        0.0         0.30  float64\nNU_NOTA_COMP2                        0.0         0.30  float64\nNU_NOTA_COMP3                        0.0         0.33  float64\nNU_NOTA_COMP4                        0.0         0.33  float64\nNU_NOTA_COMP5                        0.0         0.33  float64\nQ001                                 0.0         0.24   object\nQ002                                 0.0         0.24   object\nQ006                                 0.0         0.50   object\nQ024                                 0.0         0.15   object\nQ025                                 0.0         0.06   object\nQ026                                 0.0         0.09   object\nQ047                                 0.0         0.15   object\nTP_COR_RACA_1                        0.0         0.06    int64\nTP_COR_RACA_2                        0.0         0.06    int64\nTP_COR_RACA_3                        0.0         0.06    int64\nTP_COR_RACA_4                        0.0         0.06    int64\nTP_COR_RACA_5                        0.0         0.06    int64\nTP_ESCOLA_2                          0.0         0.06    int64\nTP_ESCOLA_3                          0.0         0.06    int64\nTP_ENSINO_1.0                        0.0         0.06    int64\nTP_ENSINO_2.0                        0.0         0.06    int64\nTP_ENSINO_3.0                        0.0         0.06    int64\nTP_DEPENDENCIA_ADM_ESC_1.0           0.0         0.06    int64\nTP_DEPENDENCIA_ADM_ESC_2.0           0.0         0.06    int64\nTP_DEPENDENCIA_ADM_ESC_3.0           0.0         0.06    int64\nTP_DEPENDENCIA_ADM_ESC_4.0           0.0         0.06    int64\nALERT: Droping columns with missing values > 0% :\nSeries([], Name: missing_perc, dtype: float64)\nALERT: Droping columns with unique values >= 100% :\nSeries([], Name: unique_perc, dtype: float64)\nCreating list with numeric features\nNumeric Feature >>>> ['NU_IDADE', 'TP_ST_CONCLUSAO', 'IN_TREINEIRO', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'TP_LINGUA', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'TP_COR_RACA_1', 'TP_COR_RACA_2', 'TP_COR_RACA_3', 'TP_COR_RACA_4', 'TP_COR_RACA_5', 'TP_ESCOLA_2', 'TP_ESCOLA_3', 'TP_ENSINO_1.0', 'TP_ENSINO_2.0', 'TP_ENSINO_3.0', 'TP_DEPENDENCIA_ADM_ESC_1.0', 'TP_DEPENDENCIA_ADM_ESC_2.0', 'TP_DEPENDENCIA_ADM_ESC_3.0', 'TP_DEPENDENCIA_ADM_ESC_4.0']\nCreating list with categoric features\nCategoric Feature >>>> ['SG_UF_RESIDENCIA', 'TP_SEXO', 'Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047']\nFeature Normalization and Encoding:\nFeature Transform in test dataframe\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3375,26) (27,) (3375,26) ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dfe68c3bb93e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_inference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelInference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codenation/enem-2/src/model_inference.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preprocessing Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Redundante, modelo não funciona com NA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codenation/enem-2/src/preprocessing.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, is_train_stage, missing_values_acceptable, unique_values_acceptable)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature Transform in test dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             df[numeric_features] = self.scaler.transform(\n\u001b[0;32m--> 122\u001b[0;31m                 df[numeric_features])\n\u001b[0m\u001b[1;32m    123\u001b[0m             df[self.categoric_features] = self.catb.transform(\n\u001b[1;32m    124\u001b[0m                 df[self.categoric_features])\n",
      "\u001b[0;32m/opt/anaconda3/envs/venv/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3375,26) (27,) (3375,26) "
     ]
    }
   ],
   "source": [
    "from model_inference import ModelInference\n",
    "y_pred = ModelInference(trained_model).predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer = data.get_columns(name_columns=[name_id], is_train_stage=False)\n",
    "df_answer[name_target] = y_pred.round(1)\n",
    "\n",
    "df_removed = data.get_removed_rows(name_columns=[name_id], is_train_stage=False)\n",
    "df_removed[name_target] = 0\n",
    "\n",
    "df_answer = pd.concat([df_answer,df_removed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.to_csv('../answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#92.12% StandardScaler->CatBoostEncoder->LinearRegression\n",
    "#93.24% StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "#93.57% Seleção manual->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "#93.58% Seleção manual(2)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento"
   ]
  }
 ]
}