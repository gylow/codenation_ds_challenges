{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596723360243",
   "display_name": "Python 3.7.7 64-bit ('venv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parâmetros gerais para a análise e processamento dos daddos\n",
    "name_target = 'NU_NOTA_MT'\n",
    "name_id = 'NU_INSCRICAO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Análise dos dados de teste e de treino\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "print(f'Train shape: {df_train.shape}, Test shape: {df_test.shape}')\n",
    "\n",
    "if name_target not in df_train.columns :\n",
    "    print('ERROR: dataframe de treino não possui target')\n",
    "    \n",
    "elif df_test.columns.size >= (df_train.drop(columns=name_target).columns.size)\\\n",
    "        and all(elem in df_test for elem in df_train.drop(columns=name_target).columns) :\n",
    "    print('ALERT: dataframes de teste e treino ok')\n",
    "\n",
    "elif all(df_train[df_test.columns].columns == df_test.columns) :\n",
    "    print('DONE: convertendo colunas dataframe de treino igual ao de teste + target')\n",
    "    df_train = pd.concat([df_train[df_test.columns], df_train[name_target]], axis=1)\n",
    "    print('DONE: gravando dataframe de treino formatado')\n",
    "    df_train.to_csv('../data/train.csv', index=False)\n",
    "else :\n",
    "    print('ERROR: colunas dos Data frames de treino e testes são diferentes')\n",
    "\n",
    "print(df_train.info())\n",
    "del df_test, df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Feature\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "var = df_train['NU_IDADE'].copy()\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.pylabtools import figsize\n",
    "%matplotlib inline\n",
    "figsize(12, 8)\n",
    "sns.set()\n",
    "sns.heatmap(df_train.corr(), square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.lineplot(var, df_train[name_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.scatterplot(var, df_train[name_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.qqplot(var, fit=True, line=\"45\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Análise de dados nulos e zerados\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "print(f'dados Nulos: {df_train[(df_train[\"TP_PRESENCA_LC\"] == 0) | (df_train[\"TP_PRESENCA_LC\"] == 2) ][name_target].unique()}')\n",
    "print(f'dados Zerados: {df_train[(df_train[\"NU_NOTA_LC\"] == 0)][name_target].unique()}')\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros para remover alunos ausentes da prova de matemática\n",
    "lin_null = [('TP_PRESENCA_LC', 0), ('TP_PRESENCA_LC', 2)]\n",
    "lin_zero = [('NU_NOTA_LC', 0)]\n",
    "\n",
    "# Parâmetro para remover alunos outliers restantes\n",
    "lin_MT_0 = [('NU_NOTA_MT', 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para a leitura dos arquivos e carregar os dataframes\n",
    "from data_source import DataSource\n",
    "data = DataSource(name_id=name_id, \n",
    "                  name_target=name_target, \n",
    "                  rows_remove=(lin_null + lin_zero), \n",
    "                  outliers_remove=lin_MT_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional manual analise columns. \n",
    "# Syntax: COLUMN_NAME       TYPE    [FILLNA ENCODE  [DROP_FIRST]] COMMENTS\n",
    "col_analise = [             \n",
    "    ('NU_INSCRICAO',        None), # only unique values\n",
    "    ('CO_UF_RESIDENCIA',    None), # duplicated\n",
    "    ('SG_UF_RESIDENCIA',    'cat',  None,   False),\n",
    "    ('NU_IDADE',            'num',  None,   False),\n",
    "    ('TP_SEXO',             'cat',  None,   False),\n",
    "    ('TP_COR_RACA',         'cat',  None,   True,   True),\n",
    "    ('TP_NACIONALIDADE',    None), # insignificant correlation\n",
    "    ('TP_ST_CONCLUSAO',     'cat',  None,   False),\n",
    "    ('TP_ANO_CONCLUIU',     None), # missing values\n",
    "    ('TP_ESCOLA',           'cat',  None,   True,   True),\n",
    "    ('TP_ENSINO',           'cat',  None,   True,   False),\n",
    "    ('IN_TREINEIRO',        'cat',  None,   False),\t\n",
    "    ('TP_DEPENDENCIA_ADM_ESC','cat',None,   True,   False),\n",
    "    ('IN_BAIXA_VISAO',      None),\t\n",
    "    ('IN_CEGUEIRA',         None), \t\n",
    "    ('IN_SURDEZ',           None), \t\n",
    "    ('IN_DISLEXIA',         None), \t\n",
    "    ('IN_DISCALCULIA',      None), \t\n",
    "    ('IN_SABATISTA',        None), \t\n",
    "    ('IN_GESTANTE',         None), \t\n",
    "    ('IN_IDOSO',            None), \t\n",
    "    ('TP_PRESENCA_CN',      None), \t\n",
    "    ('TP_PRESENCA_CH',      None), \t\n",
    "    ('TP_PRESENCA_LC',      None), \t\n",
    "    ('CO_PROVA_CN',         None), \t\n",
    "    ('CO_PROVA_CH',         None), \t\n",
    "    ('CO_PROVA_LC',         None), \t\n",
    "    ('CO_PROVA_MT',         None), \t\n",
    "    ('NU_NOTA_CN',          'num',   459.8,  False),\t\n",
    "    ('NU_NOTA_CH',          'num',   532.0,  False),\t\n",
    "    ('NU_NOTA_LC',          'num',   None,   False),\t\n",
    "    ('NU_NOTA_REDACAO',     'num',   None,   False),\t\n",
    "    ('TP_LINGUA',           'cat',   None,   False),\n",
    "    ('TP_STATUS_REDACAO',   None),\t\n",
    "    ('NU_NOTA_COMP1',       'num',   None,   False),\t\n",
    "    ('NU_NOTA_COMP2',       'num',   None,   False),\n",
    "    ('NU_NOTA_COMP3',       'num',   None,   False),\n",
    "    ('NU_NOTA_COMP4',       'num',   None,   False),\n",
    "    ('NU_NOTA_COMP5',       'num',   None,   False),\n",
    "    ('Q001',                'cat',   None,   False),\t\n",
    "    ('Q002',                'cat',   None,   False),\n",
    "    ('Q006',                'cat',   None,   False),\n",
    "    ('Q024',                'cat',   None,   False),\n",
    "    ('Q025',                'cat',   None,   False),\n",
    "    ('Q026',                'cat',   None,   False),\n",
    "    ('Q027',                None), # missing values\t\n",
    "    ('Q047',                'cat',   None,   False),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classe para o pré processamento das features\n",
    "from preprocessing import Preprocessing\n",
    "pre = Preprocessing(data, col_analise=col_analise, rfe='LR', pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classe para definir e treinar o modelo\n",
    "from model_training import ModelTraining\n",
    "model = ModelTraining(pre, model_training='RF')\n",
    "trained_model = model.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classe para rodar o modelo e gerar o resultado\n",
    "from model_inference import ModelInference\n",
    "y_pred = ModelInference(trained_model).predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pós tratamento para os alunos que não fizeram a prova:\n",
    "df_removed = data.get_removed_rows(name_columns=[name_id], is_train_stage=False)\n",
    "df_removed[name_target] = 0\n",
    "\n",
    "# Gravação da resposta\n",
    "df_answer = data.get_columns(name_columns=[name_id], is_train_stage=False)\n",
    "df_answer[name_target] = y_pred.round(2)\n",
    "df_answer = pd.concat([df_answer,df_removed])\n",
    "df_answer.to_csv('../answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histórico das submissões\n",
    "# LinearRegression:\n",
    "# 92.12%  StandardScaler->CatBoostEncoder->LinearRegression\n",
    "# 93.24%  StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.57%  Seleção manual->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.58%  Seleção manual(2)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.61%  Seleção manual(3)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.60%  Seleção manual(3)->Seleção RFE(LinearRegression,50%)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.52%  Seleção manual(3)->Seleção RFE(LinearRegression,PCA(.95))->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# RandomForestRegressor:\n",
    "# 93.57%  Seleção manual(3)->Seleção RFE(LinearRegression,PCA(.95))->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.56%  Seleção manual(3)->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.61%  Seleção manual(3)->Seleção RFE(LinearRegression,50%)->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.59%  Seleção manual(3)->Seleção RFE(DecisionTreeRegressor,50%)->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.55%  Seleção manual(3)->Seleção RFE(DecisionTreeRegressor,PCA(.95))->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.57%  Trat. Outliers->Seleção manual(3)->Seleção RFE(LinearRegression,50%)->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.60%  Trat. Outliers->Seleção manual(3)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.17%  Trat. Outliers->Seleção RFE(LinearRegression,50%)->StandardScaler->CatBoostEncoder->RandomForestRegressor->Pós Processamento\n",
    "# 93.07%  Trat. Outliers->Seleção RFE(LinearRegression,50%)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento"
   ]
  }
 ]
}