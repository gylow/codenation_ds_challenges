{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596632095764",
   "display_name": "Python 3.7.7 64-bit ('venv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_target = 'NU_NOTA_MT'\n",
    "name_id = 'NU_INSCRICAO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analisa os dados de teste e de treino\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "print(f'Train shape: {df_train.shape}, Test shape: {df_test.shape}')\n",
    "\n",
    "if name_target not in df_train.columns :\n",
    "    print('ERROR: dataframe de treino não possui target')\n",
    "    \n",
    "elif df_test.columns.size >= (df_train.drop(columns=name_target).columns.size)\\\n",
    "        and all(elem in df_test for elem in df_train.drop(columns=name_target).columns) :\n",
    "    print('ALERT: dataframes de teste e treino ok')\n",
    "\n",
    "elif all(df_train[df_test.columns].columns == df_test.columns) :\n",
    "    print('DONE: convertendo colunas dataframe de treino igual ao de teste + target')\n",
    "    df_train = pd.concat([df_train[df_test.columns], df_train[name_target]], axis=1)\n",
    "    print('DONE: gravando dataframe de treino formatado')\n",
    "    df_train.to_csv('../data/train.csv', index=False)\n",
    "else :\n",
    "    print('ERROR: colunas dos Data frames de treino e testes são diferentes')\n",
    "\n",
    "print(df_train.info())\n",
    "del df_test, df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Análise de dados nulos e zerados\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "print(f'dados Nulos: {df_train[(df_train[\"TP_PRESENCA_LC\"] == 0) | (df_train[\"TP_PRESENCA_LC\"] == 2) ][name_target].unique()}')\n",
    "print(f'dados Zerados: {df_train[(df_train[\"NU_NOTA_LC\"] == 0)][name_target].unique()}')\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_source import DataSource\n",
    "lin_null = [('TP_PRESENCA_LC', 0), ('TP_PRESENCA_LC', 2)]\n",
    "lin_zero = [('NU_NOTA_LC', 0)]\n",
    "data = DataSource(name_id=name_id, name_target=name_target, rows_remove=(lin_null + lin_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Feature\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from IPython.core.pylabtools import figsize\n",
    "%matplotlib inline\n",
    "figsize(12, 8)\n",
    "sns.set()\n",
    "sns.heatmap(df_train.corr(), square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = df_train['TP_STATUS_REDACAO']\n",
    "print(var.value_counts(dropna=False))\n",
    "print(f'mean: {var.mean()}')\n",
    "print(f'median: {var.median()}')\n",
    "print(f'mode: {var.mode()}')\n",
    "sns.distplot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.scatterplot(var, df_train[name_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.lineplot(var, df_train[name_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.qqplot(var, fit=True, line=\"45\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional manual analise columns\n",
    "col_analise = [             #TYPE  ->[FILLNA  ENCODE ->[DROP_FIRST]]\n",
    "    ('NU_INSCRICAO',        None), # only unique values\n",
    "    ('CO_UF_RESIDENCIA',    None), # duplicated\n",
    "    ('SG_UF_RESIDENCIA',    'cat',  None,   False),\n",
    "    ('NU_IDADE',            'num',  None,   False),\n",
    "    ('TP_SEXO',             'cat',  None,   False),\n",
    "    #('TP_COR_RACA',         'cat'),\n",
    "    ('TP_COR_RACA',         'cat',  None,   True,   True),\n",
    "    ('TP_NACIONALIDADE',    None), # insignificant correlation\n",
    "    ('TP_ST_CONCLUSAO',     'cat',  None,   False),\n",
    "    ('TP_ANO_CONCLUIU',     None), # missing values\n",
    "    #('TP_ESCOLA',           False),\n",
    "    ('TP_ESCOLA',           'cat',  None,   True,   True),\n",
    "    ('TP_ENSINO',           'cat',  None,   True,   False),\n",
    "    ('IN_TREINEIRO',        'cat',  None,   False),\t\n",
    "    ('TP_DEPENDENCIA_ADM_ESC','cat',None,   True,   False),\n",
    "    ('IN_BAIXA_VISAO',      None),\t\n",
    "    ('IN_CEGUEIRA',         None), \t\n",
    "    ('IN_SURDEZ',           None), \t\n",
    "    ('IN_DISLEXIA',         None), \t\n",
    "    ('IN_DISCALCULIA',      None), \t\n",
    "    ('IN_SABATISTA',        None), \t\n",
    "    ('IN_GESTANTE',         None), \t\n",
    "    ('IN_IDOSO',            None), \t\n",
    "    ('TP_PRESENCA_CN',      None), \t\n",
    "    ('TP_PRESENCA_CH',      None), \t\n",
    "    ('TP_PRESENCA_LC',      None), \t\n",
    "    ('CO_PROVA_CN',         None), \t\n",
    "    ('CO_PROVA_CH',         None), \t\n",
    "    ('CO_PROVA_LC',         None), \t\n",
    "    ('CO_PROVA_MT',         None), \t\n",
    "    ('NU_NOTA_CN',          'num',   459.8,  False),\t\n",
    "    ('NU_NOTA_CH',          'num',   532.0,  False),\t\n",
    "    ('NU_NOTA_LC',          'num',   None,   False),\t\n",
    "    #('NU_NOTA_REDACAO',     'num',   None,   False),\t\n",
    "    ('NU_NOTA_REDACAO',     None),\t\n",
    "    ('TP_LINGUA',           'cat',   None,   False),\n",
    "    ('TP_STATUS_REDACAO',   None),\t\n",
    "    #('NU_NOTA_COMP1',       None),\t\n",
    "    ('NU_NOTA_COMP1',       'num',   None,   False),\t\n",
    "    #('NU_NOTA_COMP2',       None),\t\n",
    "    ('NU_NOTA_COMP2',       'num',   None,   False),\n",
    "    #('NU_NOTA_COMP3',       None),\t\n",
    "    ('NU_NOTA_COMP3',       'num',   None,   False),\n",
    "    #('NU_NOTA_COMP4',       None),\n",
    "    ('NU_NOTA_COMP4',       'num',   None,   False),\n",
    "    #('NU_NOTA_COMP5',       None),\n",
    "    ('NU_NOTA_COMP5',       'num',   None,   False),\n",
    "    ('Q001',                'cat',   None,   False),\t\n",
    "    ('Q002',                'cat',   None,   False),\n",
    "    ('Q006',                'cat',   None,   False),\n",
    "    ('Q024',                'cat',   None,   False),\n",
    "    ('Q025',                'cat',   None,   False),\n",
    "    #('Q026',                False),\t\n",
    "    ('Q026',                'cat',   None,   False),\n",
    "    ('Q027',                None), # missing values\t\n",
    "    ('Q047',                'cat',   None,   False),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessing\n",
    "pre = Preprocessing(data, col_analise=col_analise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#testes\n",
    "df_new = pre.process()[0]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from experiments import Experiments\n",
    "#Experiments(data).run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training import ModelTraining\n",
    "model = ModelTraining(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training preprocessing\ndrop: NU_INSCRICAO\ndrop: CO_UF_RESIDENCIA\nuse: SG_UF_RESIDENCIA\nuse: NU_IDADE\nuse: TP_SEXO\nuse: TP_COR_RACA\n\tencode: [0 1 2 3 4 5]\n\tdrop value: 0\ndrop: TP_NACIONALIDADE\nuse: TP_ST_CONCLUSAO\ndrop: TP_ANO_CONCLUIU\nuse: TP_ESCOLA\n\tencode: [1 2 3 4]\n\tdrop value: 1\nuse: TP_ENSINO\n\tencode: [1. 2. 3.]\nuse: IN_TREINEIRO\nuse: TP_DEPENDENCIA_ADM_ESC\n\tencode: [1. 2. 3. 4.]\ndrop: IN_BAIXA_VISAO\ndrop: IN_CEGUEIRA\ndrop: IN_SURDEZ\ndrop: IN_DISLEXIA\ndrop: IN_DISCALCULIA\ndrop: IN_SABATISTA\ndrop: IN_GESTANTE\ndrop: IN_IDOSO\ndrop: TP_PRESENCA_CN\ndrop: TP_PRESENCA_CH\ndrop: TP_PRESENCA_LC\ndrop: CO_PROVA_CN\ndrop: CO_PROVA_CH\ndrop: CO_PROVA_LC\ndrop: CO_PROVA_MT\nuse: NU_NOTA_CN\n\tfill na with: 459.8\nuse: NU_NOTA_CH\n\tfill na with: 532.0\nuse: NU_NOTA_LC\ndrop: NU_NOTA_REDACAO\nuse: TP_LINGUA\ndrop: TP_STATUS_REDACAO\nuse: NU_NOTA_COMP1\nuse: NU_NOTA_COMP2\nuse: NU_NOTA_COMP3\nuse: NU_NOTA_COMP4\nuse: NU_NOTA_COMP5\nuse: Q001\nuse: Q002\nuse: Q006\nuse: Q024\nuse: Q025\nuse: Q026\ndrop: Q027\nuse: Q047\nALERT: Numeric Feature >>>> ['NU_IDADE', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\nALERT: Categoric Feature >>>> ['SG_UF_RESIDENCIA', 'TP_SEXO', 'TP_COR_RACA_1', 'TP_COR_RACA_2', 'TP_COR_RACA_3', 'TP_COR_RACA_4', 'TP_COR_RACA_5', 'TP_ST_CONCLUSAO', 'TP_ESCOLA_2', 'TP_ESCOLA_3', 'TP_ENSINO_1.0', 'TP_ENSINO_2.0', 'TP_ENSINO_3.0', 'IN_TREINEIRO', 'TP_DEPENDENCIA_ADM_ESC_1.0', 'TP_DEPENDENCIA_ADM_ESC_2.0', 'TP_DEPENDENCIA_ADM_ESC_3.0', 'TP_DEPENDENCIA_ADM_ESC_4.0', 'TP_LINGUA', 'Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047']\nSetting Y as target and Removing target from train dataframe\nALERT: Select features\nN components PCA: 12\nNumeric Feature Selected >>>> ['NU_IDADE', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_COMP2', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\nCategoric Feature Selected >>>> ['TP_SEXO', 'TP_COR_RACA_2', 'TP_COR_RACA_4', 'TP_ST_CONCLUSAO', 'TP_ESCOLA_2', 'TP_ENSINO_1.0', 'TP_ENSINO_3.0', 'TP_DEPENDENCIA_ADM_ESC_1.0', 'TP_DEPENDENCIA_ADM_ESC_3.0', 'TP_LINGUA', 'Q002', 'Q024', 'Q026']\nFeature fit and transform in train dataframe\nTraining Model\n"
    }
   ],
   "source": [
    "trained_model = model.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Preprocessing Data\ndrop: NU_INSCRICAO\ndrop: CO_UF_RESIDENCIA\nuse: SG_UF_RESIDENCIA\nuse: NU_IDADE\nuse: TP_SEXO\nuse: TP_COR_RACA\n\tencode: [0 1 2 3 4 5]\n\tdrop value: 0\ndrop: TP_NACIONALIDADE\nuse: TP_ST_CONCLUSAO\ndrop: TP_ANO_CONCLUIU\nuse: TP_ESCOLA\n\tencode: [1 2 3]\n\tdrop value: 1\nuse: TP_ENSINO\n\tencode: [1. 2. 3.]\nuse: IN_TREINEIRO\nuse: TP_DEPENDENCIA_ADM_ESC\n\tencode: [1. 2. 3. 4.]\ndrop: IN_BAIXA_VISAO\ndrop: IN_CEGUEIRA\ndrop: IN_SURDEZ\ndrop: IN_DISLEXIA\ndrop: IN_DISCALCULIA\ndrop: IN_SABATISTA\ndrop: IN_GESTANTE\ndrop: IN_IDOSO\ndrop: TP_PRESENCA_CN\ndrop: TP_PRESENCA_CH\ndrop: TP_PRESENCA_LC\ndrop: CO_PROVA_CN\ndrop: CO_PROVA_CH\ndrop: CO_PROVA_LC\ndrop: CO_PROVA_MT\nuse: NU_NOTA_CN\n\tfill na with: 459.8\nuse: NU_NOTA_CH\n\tfill na with: 532.0\nuse: NU_NOTA_LC\ndrop: NU_NOTA_REDACAO\nuse: TP_LINGUA\ndrop: TP_STATUS_REDACAO\nuse: NU_NOTA_COMP1\nuse: NU_NOTA_COMP2\nuse: NU_NOTA_COMP3\nuse: NU_NOTA_COMP4\nuse: NU_NOTA_COMP5\nuse: Q001\nuse: Q002\nuse: Q006\nuse: Q024\nuse: Q025\nuse: Q026\ndrop: Q027\nuse: Q047\nALERT: Numeric Feature >>>> ['NU_IDADE', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_COMP2', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\nALERT: Categoric Feature >>>> ['TP_SEXO', 'TP_COR_RACA_2', 'TP_COR_RACA_4', 'TP_ST_CONCLUSAO', 'TP_ESCOLA_2', 'TP_ENSINO_1.0', 'TP_ENSINO_3.0', 'TP_DEPENDENCIA_ADM_ESC_1.0', 'TP_DEPENDENCIA_ADM_ESC_3.0', 'TP_LINGUA', 'Q002', 'Q024', 'Q026']\nFeature Transform in test dataframe\nPredicting\nSaving Files\n"
    }
   ],
   "source": [
    "from model_inference import ModelInference\n",
    "y_pred = ModelInference(trained_model).predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer = data.get_columns(name_columns=[name_id], is_train_stage=False)\n",
    "df_answer[name_target] = y_pred.round(1)\n",
    "\n",
    "df_removed = data.get_removed_rows(name_columns=[name_id], is_train_stage=False)\n",
    "df_removed[name_target] = 0\n",
    "\n",
    "df_answer = pd.concat([df_answer,df_removed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.to_csv('../answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histórico das submissões\n",
    "# 92.12% StandardScaler->CatBoostEncoder->LinearRegression\n",
    "# 93.24% StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.57% Seleção manual->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.58% Seleção manual(2)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.61% Seleção manual(3)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.60% Seleção manual(3)->Seleção RFE(50%)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento\n",
    "# 93.52% Seleção manual(3)->Seleção RFE(12)->StandardScaler->CatBoostEncoder->LinearRegression->Pós Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}